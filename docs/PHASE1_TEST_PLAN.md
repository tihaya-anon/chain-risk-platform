# Phase 1 æµ‹è¯•è®¡åˆ’

> ç›®æ ‡ï¼šéªŒè¯æ ¸å¿ƒæ•°æ®æµ `é“¾ä¸Šæ•°æ® â†’ Kafka â†’ Flink â†’ PostgreSQL` å®Œæ•´å¯ç”¨

## ğŸ“‹ æµ‹è¯•æ¦‚è§ˆ

| æµ‹è¯•ç±»å‹ | ç»„ä»¶ | çŠ¶æ€ |
|----------|------|------|
| å•å…ƒæµ‹è¯• | data-ingestion | ğŸ”² |
| å•å…ƒæµ‹è¯• | stream-processor | ğŸ”² |
| é›†æˆæµ‹è¯• | åŸºç¡€è®¾æ–½ | ğŸ”² |
| é›†æˆæµ‹è¯• | ç«¯åˆ°ç«¯æ•°æ®æµ | ğŸ”² |

---

## 1ï¸âƒ£ åŸºç¡€è®¾æ–½éªŒè¯

### 1.1 Docker Compose å¯åŠ¨æµ‹è¯•

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# éªŒè¯æ‰€æœ‰å®¹å™¨è¿è¡Œæ­£å¸¸
docker-compose ps
```

**é¢„æœŸç»“æœï¼š** æ‰€æœ‰å®¹å™¨çŠ¶æ€ä¸º `Up`

| æœåŠ¡ | ç«¯å£ | å¥åº·æ£€æŸ¥ |
|------|------|----------|
| PostgreSQL | 5432 | `pg_isready -U chainrisk` |
| Kafka | 9092 | `kafka-topics --bootstrap-server localhost:9092 --list` |
| Redis | 6379 | `redis-cli ping` |
| Neo4j | 7474/7687 | è®¿é—® http://localhost:7474 |
| Nacos | 8848 | è®¿é—® http://localhost:8848/nacos |
| Prometheus | 9090 | è®¿é—® http://localhost:9090 |
| Grafana | 3001 | è®¿é—® http://localhost:3001 |

### 1.2 æ•°æ®åº“ Schema éªŒè¯

```bash
# è¿æ¥æ•°æ®åº“
docker exec -it postgres psql -U chainrisk -d chainrisk

# éªŒè¯ schema å­˜åœ¨
\dn

# éªŒè¯è¡¨å­˜åœ¨
\dt chain_data.*
\dt risk.*
\dt alert.*
```

**é¢„æœŸç»“æœï¼š**
- Schema: `chain_data`, `risk`, `alert`
- è¡¨: `transfers`, `transactions`, `address_scores`, `address_labels`, `alerts`, `rules`, `processing_state`

### 1.3 Kafka Topic åˆ›å»ºæµ‹è¯•

```bash
# åˆ›å»º topic
docker exec -it kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic chain-transactions \
  --partitions 3 \
  --replication-factor 1

# éªŒè¯ topic
docker exec -it kafka kafka-topics --describe \
  --bootstrap-server localhost:9092 \
  --topic chain-transactions
```

---

## 2ï¸âƒ£ Data Ingestion æœåŠ¡æµ‹è¯•

### 2.1 å•å…ƒæµ‹è¯•

#### 2.1.1 Config åŠ è½½æµ‹è¯•
```go
// test/config_test.go
func TestLoadConfig(t *testing.T) {
    cfg, err := config.Load("../configs/config.yaml")
    assert.NoError(t, err)
    assert.Equal(t, "ethereum", cfg.Blockchain.Network)
}
```

#### 2.1.2 Etherscan Client æµ‹è¯•
```go
// test/client_test.go
func TestGetLatestBlockNumber(t *testing.T) {
    client, _ := client.NewEtherscanClient("ethereum", baseURL, apiKey, 5)
    blockNum, err := client.GetLatestBlockNumber(context.Background())
    assert.NoError(t, err)
    assert.Greater(t, blockNum, uint64(0))
}
```

#### 2.1.3 Transfer æå–æµ‹è¯•
```go
// test/service_test.go
func TestExtractNativeTransfer(t *testing.T) {
    tx := &model.Transaction{
        Hash:  "0x123",
        From:  "0xabc",
        To:    "0xdef",
        Value: big.NewInt(1000000000000000000), // 1 ETH
    }
    transfer := service.extractNativeTransfer(tx)
    assert.Equal(t, "native", transfer.TransferType)
    assert.Equal(t, "ETH", transfer.TokenSymbol)
}
```

### 2.2 é›†æˆæµ‹è¯•

#### 2.2.1 Kafka Producer æµ‹è¯•

```bash
# å¯åŠ¨æœåŠ¡ï¼ˆmock æ¨¡å¼æˆ–çœŸå® APIï¼‰
cd data-ingestion
go run ./cmd/ingestion -config configs/config.yaml

# å¦ä¸€ä¸ªç»ˆç«¯æ¶ˆè´¹æ¶ˆæ¯éªŒè¯
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic chain-transactions \
  --from-beginning \
  --max-messages 5
```

**é¢„æœŸç»“æœï¼š** èƒ½çœ‹åˆ° JSON æ ¼å¼çš„ ChainEvent æ¶ˆæ¯

#### 2.2.2 æ‰‹åŠ¨å‘é€æµ‹è¯•æ¶ˆæ¯

```bash
# å‘é€æµ‹è¯•æ¶ˆæ¯åˆ° Kafka
echo '{"eventType":"transaction","network":"ethereum","blockNumber":12345678,"timestamp":"2024-01-01T00:00:00Z","data":{"hash":"0xtest","blockNumber":12345678,"from":"0xabc","to":"0xdef","value":"1000000000000000000"}}' | \
docker exec -i kafka kafka-console-producer \
  --bootstrap-server localhost:9092 \
  --topic chain-transactions
```

---

## 3ï¸âƒ£ Stream Processor æœåŠ¡æµ‹è¯•

### 3.1 å•å…ƒæµ‹è¯•

#### 3.1.1 ChainEvent ååºåˆ—åŒ–æµ‹è¯•
```java
// src/test/java/com/chainrisk/stream/parser/ChainEventDeserializerTest.java
@Test
void testDeserialize() {
    String json = "{\"eventType\":\"transaction\",\"network\":\"ethereum\"}";
    ChainEventDeserializer deserializer = new ChainEventDeserializer();
    ChainEvent event = deserializer.deserialize(json.getBytes());
    assertEquals("transaction", event.getEventType());
    assertEquals("ethereum", event.getNetwork());
}
```

#### 3.1.2 TransferParser æµ‹è¯•
```java
// src/test/java/com/chainrisk/stream/parser/TransferParserTest.java
@Test
void testParseNativeTransfer() {
    ChainEvent event = createTestTransactionEvent();
    TransferParser parser = new TransferParser();
    List<Transfer> transfers = new ArrayList<>();
    parser.flatMap(event, transfers::add);
    assertEquals(1, transfers.size());
    assertEquals("native", transfers.get(0).getTransferType());
}
```

### 3.2 é›†æˆæµ‹è¯•

#### 3.2.1 æœ¬åœ° Flink è¿è¡Œæµ‹è¯•

```bash
# æ„å»º
cd processing
mvn clean package -pl stream-processor -am -DskipTests

# æœ¬åœ°è¿è¡Œï¼ˆMiniCluster æ¨¡å¼ï¼‰
java -cp stream-processor/target/stream-processor-1.0.0-SNAPSHOT.jar \
  com.chainrisk.stream.StreamProcessorApp \
  --kafka.brokers=localhost:9092 \
  --jdbc.url=jdbc:postgresql://localhost:5432/chainrisk
```

#### 3.2.2 éªŒè¯æ•°æ®å†™å…¥ PostgreSQL

```sql
-- è¿æ¥æ•°æ®åº“åæ‰§è¡Œ
SELECT COUNT(*) FROM chain_data.transfers;

SELECT * FROM chain_data.transfers 
ORDER BY created_at DESC 
LIMIT 10;
```

**é¢„æœŸç»“æœï¼š** èƒ½çœ‹åˆ°ä» Kafka æ¶ˆè´¹å¹¶å†™å…¥çš„ Transfer è®°å½•

---

## 4ï¸âƒ£ ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•

### 4.1 å®Œæ•´æ•°æ®æµæµ‹è¯•

```
æµ‹è¯•æµç¨‹ï¼š
1. å¯åŠ¨åŸºç¡€è®¾æ–½ (docker-compose up -d)
2. å¯åŠ¨ stream-processor
3. å¯åŠ¨ data-ingestion
4. ç­‰å¾… 1-2 åˆ†é’Ÿ
5. éªŒè¯æ•°æ®åº“ä¸­æœ‰æ•°æ®
```

#### 4.1.1 æµ‹è¯•è„šæœ¬

```bash
#!/bin/bash
# scripts/test-e2e.sh

set -e

echo "=== Phase 1 End-to-End Test ==="

# 1. æ£€æŸ¥åŸºç¡€è®¾æ–½
echo "[1/5] Checking infrastructure..."
docker-compose ps | grep -q "Up" || { echo "Infrastructure not running"; exit 1; }

# 2. æ£€æŸ¥ Kafka topic
echo "[2/5] Checking Kafka topic..."
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list | grep -q "chain-transactions" || {
    echo "Creating topic..."
    docker exec kafka kafka-topics --create --bootstrap-server localhost:9092 \
        --topic chain-transactions --partitions 3 --replication-factor 1
}

# 3. å‘é€æµ‹è¯•æ¶ˆæ¯
echo "[3/5] Sending test message to Kafka..."
TEST_MSG='{"eventType":"transfer","network":"ethereum","blockNumber":12345678,"timestamp":"2024-01-01T00:00:00Z","data":{"txHash":"0xtest123","blockNumber":12345678,"logIndex":0,"from":"0xaaaa","to":"0xbbbb","value":"1000000000000000000","tokenSymbol":"ETH","tokenDecimal":18,"transferType":"native"}}'
echo $TEST_MSG | docker exec -i kafka kafka-console-producer --bootstrap-server localhost:9092 --topic chain-transactions

# 4. ç­‰å¾…å¤„ç†
echo "[4/5] Waiting for processing (10s)..."
sleep 10

# 5. éªŒè¯æ•°æ®åº“
echo "[5/5] Verifying database..."
RESULT=$(docker exec postgres psql -U chainrisk -d chainrisk -t -c "SELECT COUNT(*) FROM chain_data.transfers WHERE tx_hash='0xtest123'")
if [ "$RESULT" -gt 0 ]; then
    echo "âœ… SUCCESS: Data found in database"
    docker exec postgres psql -U chainrisk -d chainrisk -c "SELECT tx_hash, from_address, to_address, value, transfer_type FROM chain_data.transfers WHERE tx_hash='0xtest123'"
else
    echo "âŒ FAILED: No data found in database"
    exit 1
fi

echo "=== Test Complete ==="
```

### 4.2 æ€§èƒ½åŸºå‡†æµ‹è¯•

```bash
# å‘é€ 1000 æ¡æµ‹è¯•æ¶ˆæ¯
for i in {1..1000}; do
    echo "{\"eventType\":\"transfer\",\"network\":\"ethereum\",\"blockNumber\":$i,\"timestamp\":\"2024-01-01T00:00:00Z\",\"data\":{\"txHash\":\"0xperf$i\",\"blockNumber\":$i,\"logIndex\":0,\"from\":\"0xaaaa\",\"to\":\"0xbbbb\",\"value\":\"1000\",\"transferType\":\"native\"}}"
done | docker exec -i kafka kafka-console-producer --bootstrap-server localhost:9092 --topic chain-transactions

# ç­‰å¾…å¤„ç†
sleep 30

# éªŒè¯
docker exec postgres psql -U chainrisk -d chainrisk -c "SELECT COUNT(*) FROM chain_data.transfers WHERE tx_hash LIKE '0xperf%'"
```

**é¢„æœŸç»“æœï¼š** 1000 æ¡è®°å½•å…¨éƒ¨å†™å…¥ï¼Œå¤„ç†æ—¶é—´ < 30ç§’

---

## 5ï¸âƒ£ æµ‹è¯•æ£€æŸ¥æ¸…å•

### Phase 1 å®Œæˆæ ‡å‡†

| # | æ£€æŸ¥é¡¹ | éªŒè¯æ–¹æ³• | çŠ¶æ€ |
|---|--------|----------|------|
| 1 | Docker Compose æ‰€æœ‰æœåŠ¡æ­£å¸¸å¯åŠ¨ | `docker-compose ps` | ğŸ”² |
| 2 | PostgreSQL schema å’Œè¡¨åˆ›å»ºæˆåŠŸ | `\dt chain_data.*` | ğŸ”² |
| 3 | Kafka topic åˆ›å»ºæˆåŠŸ | `kafka-topics --list` | ğŸ”² |
| 4 | data-ingestion èƒ½è¿æ¥ Etherscan API | æŸ¥çœ‹æ—¥å¿— | ğŸ”² |
| 5 | data-ingestion èƒ½å‘é€æ¶ˆæ¯åˆ° Kafka | kafka-console-consumer | ğŸ”² |
| 6 | stream-processor èƒ½æ¶ˆè´¹ Kafka æ¶ˆæ¯ | æŸ¥çœ‹ Flink æ—¥å¿— | ğŸ”² |
| 7 | stream-processor èƒ½å†™å…¥ PostgreSQL | SQL æŸ¥è¯¢ | ğŸ”² |
| 8 | ç«¯åˆ°ç«¯æ•°æ®æµæ­£å¸¸ | E2E æµ‹è¯•è„šæœ¬ | ğŸ”² |
| 9 | æ•°æ®æ ¼å¼æ­£ç¡®ï¼ˆTransfer å­—æ®µå®Œæ•´ï¼‰ | SQL æŸ¥è¯¢éªŒè¯ | ğŸ”² |
| 10 | æ— æ˜æ˜¾æ€§èƒ½é—®é¢˜ | 1000 æ¡ < 30s | ğŸ”² |

### é€šè¿‡æ ‡å‡†

- âœ… **10/10 é€šè¿‡**: Phase 1 å®Œæˆï¼Œå¯è¿›å…¥ Phase 2
- âš ï¸ **8-9/10 é€šè¿‡**: æœ‰å°é—®é¢˜ï¼Œè®°å½•åå¯ç»§ç»­
- âŒ **< 8/10 é€šè¿‡**: éœ€è¦ä¿®å¤åé‡æ–°æµ‹è¯•

---

## 6ï¸âƒ£ å·²çŸ¥é™åˆ¶å’Œå¾…æ”¹è¿›

### å½“å‰é™åˆ¶
1. ERC20 Transfer ä»…æ”¯æŒä» input è§£æï¼Œä¸æ”¯æŒ event log è§£æ
2. æœªå®ç° checkpoint æŒä¹…åŒ–ï¼ˆé‡å¯åä»å¤´æ¶ˆè´¹ï¼‰
3. æœªå®ç° exactly-once è¯­ä¹‰

### Phase 2 å‰éœ€å®Œæˆ
- [ ] è¡¥å……å•å…ƒæµ‹è¯•
- [ ] æ·»åŠ  ERC20 event log è§£æï¼ˆå¯é€‰ï¼‰
- [ ] é…ç½® Flink checkpoint åˆ°å¤–éƒ¨å­˜å‚¨

---

## ğŸ“ æµ‹è¯•æ‰§è¡Œè®°å½•

| æ—¥æœŸ | æ‰§è¡Œäºº | ç»“æœ | å¤‡æ³¨ |
|------|--------|------|------|
| - | - | - | - |
